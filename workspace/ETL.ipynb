{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a95990-b807-498e-9b53-7eabfe755261",
   "metadata": {},
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d11de01-2d68-4e3f-a34b-e757fd0a22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, BooleanType, StringType, IntegerType, LongType, ArrayType, DateType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb78b08-f2d5-4fc8-abfa-0339adf3adcf",
   "metadata": {},
   "source": [
    "# IO manger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547663a2-cd79-4d1d-9a40-3c722c66e9e6",
   "metadata": {},
   "source": [
    "Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d974d2e-1f57-4624-8a64-8241b91ea991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def SparkIO(conf: SparkConf = SparkConf()):\n",
    "    app_name = conf.get(\"spark.app.name\")\n",
    "    master = conf.get(\"spark.master\")\n",
    "    print(f'Create SparkSession app {app_name} with {master} mode')\n",
    "    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "    try:\n",
    "        yield spark\n",
    "    finally:\n",
    "        print(f'Stop SparkSession app {app_name}')\n",
    "        spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6828f914-a967-4c98-bc39-cf2a86639d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.errors import ConnectionFailure\n",
    "from contextlib import contextmanager\n",
    "import os\n",
    "\n",
    "@contextmanager\n",
    "def MongodbIO():\n",
    "    user = os.getenv(\"MONGODB_USER\")\n",
    "    password = os.getenv(\"MONGODB_PASSWORD\")\n",
    "    uri = f\"mongodb+srv://{user}:{password}@python.zynpktu.mongodb.net/?retryWrites=true&w=majority\"\n",
    "    try:\n",
    "        client = MongoClient(uri)\n",
    "        print(f\"MongoDB Connected\")\n",
    "        yield client\n",
    "    except ConnectionFailure:\n",
    "        print(f\"Failed to connect with MongoDB\")\n",
    "        raise ConnectionFailure\n",
    "    finally:\n",
    "        print(\"Close connection to MongoDB\")\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9948d-4ad7-46ca-8716-560c613e3e24",
   "metadata": {},
   "source": [
    "## Bronze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190ba553-98b8-4884-9899-4b95b7b9e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSchema(table_name):\n",
    "    \"\"\"This function create Pyspark Schema\"\"\"\n",
    "    artist_schema = StructType([\n",
    "        StructField(\"_id\", StringType(), True),\n",
    "        StructField(\n",
    "            \"external_urls\",\n",
    "            StructType([\n",
    "                StructField(\"spotify\", StringType(), True)\n",
    "            ])\n",
    "        ),\n",
    "        StructField(\n",
    "            \"followers\", \n",
    "            StructType([\n",
    "                StructField(\"href\", StringType(), True),\n",
    "                StructField(\"total\", IntegerType(), True)\n",
    "            ])\n",
    "        ),\n",
    "        StructField(\n",
    "            \"genres\",\n",
    "            ArrayType(StringType(), True)      \n",
    "        ),\n",
    "        StructField(\"href\", StringType(), True),\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\n",
    "            \"images\",\n",
    "            ArrayType(\n",
    "                StructType([\n",
    "                    StructField(\"height\", IntegerType(), True),\n",
    "                    StructField(\"url\", StringType(), True),\n",
    "                    StructField(\"width\", IntegerType(), True)\n",
    "                ])\n",
    "            )\n",
    "        ),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"popularity\", IntegerType(), True),\n",
    "        StructField(\"type\", StringType(), True),\n",
    "        StructField(\"uri\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    album_schema = StructType([\n",
    "        StructField(\"_id\", StringType(), True),\n",
    "        StructField(\"album_type\", StringType(), True),\n",
    "        StructField(\n",
    "            \"copyrights\",\n",
    "            ArrayType(\n",
    "                StructType([\n",
    "                    StructField(\"text\", StringType(), True),\n",
    "                    StructField(\"type\", StringType(), True)\n",
    "                ])\n",
    "            )\n",
    "        ),\n",
    "        StructField(\n",
    "            \"external_ids\",\n",
    "            StructType([\n",
    "                StructField(\"upc\", StringType(), True)\n",
    "            ])\n",
    "        ),\n",
    "        StructField(\n",
    "            \"external_urls\",\n",
    "            StructType([\n",
    "                StructField(\"spotify\", StringType(), True)\n",
    "            ])\n",
    "        ),\n",
    "        StructField(\n",
    "            \"genres\",\n",
    "            ArrayType(StringType(), True)\n",
    "        ),\n",
    "        StructField(\"href\", StringType(), True),\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\n",
    "            \"images\",\n",
    "            ArrayType(\n",
    "                StructType([\n",
    "                    StructField(\"height\", IntegerType(), True),\n",
    "                    StructField(\"url\", StringType(), True),\n",
    "                    StructField(\"width\", IntegerType(), True)\n",
    "                ])\n",
    "            )\n",
    "        ),\n",
    "        StructField(\"label\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"popularity\", IntegerType(), True),\n",
    "        StructField(\"release_date\", StringType(), True),\n",
    "        StructField(\"release_date_precision\", StringType(), True),\n",
    "        StructField(\"total_tracks\", IntegerType(), True),\n",
    "        StructField(\"type\", StringType(), True),\n",
    "        StructField(\"uri\", StringType(), True),\n",
    "        StructField(\"artist_id\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    track_schema = StructType([\n",
    "        StructField(\"_id\", StringType(), True),\n",
    "        StructField(\"disc_number\", IntegerType(), True),\n",
    "        StructField(\"duration_ms\", LongType(), True),\n",
    "        StructField(\"explicit\", BooleanType(), True),\n",
    "        StructField(\n",
    "            \"external_ids\",\n",
    "            StructType([\n",
    "                StructField(\"isrc\", StringType(), True)\n",
    "            ])\n",
    "        ),\n",
    "        StructField(\n",
    "            \"external_urls\",\n",
    "            StructType([\n",
    "                StructField(\"spotify\", StringType(), True)\n",
    "            ])\n",
    "        ),\n",
    "        StructField(\"href\", StringType(), True),\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"is_local\", BooleanType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"popularity\", IntegerType(), True),\n",
    "        StructField(\"preview_url\", StringType(), True),\n",
    "        StructField(\"track_number\", IntegerType(), True),\n",
    "        StructField(\"type\", StringType(), True),\n",
    "        StructField(\"uri\", StringType(), True),\n",
    "        StructField(\"artist_id\", StringType(), True),\n",
    "        StructField(\"album_id\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    track_features_schema = StructType([\n",
    "        StructField(\"_id\", StringType(), True),\n",
    "        StructField(\"danceability\", DoubleType(), True),\n",
    "        StructField(\"energy\", DoubleType(), True),\n",
    "        StructField(\"key\", IntegerType(), True),\n",
    "        StructField(\"loudness\", DoubleType(), True),\n",
    "        StructField(\"mode\", IntegerType(), True),\n",
    "        StructField(\"speechiness\", DoubleType(), True),\n",
    "        StructField(\"acousticness\", DoubleType(), True),\n",
    "        StructField(\"instrumentalness\", DoubleType(), True),\n",
    "        StructField(\"liveness\", DoubleType(), True),\n",
    "        StructField(\"valence\", DoubleType(), True),\n",
    "        StructField(\"tempo\", DoubleType(), True),\n",
    "        StructField(\"type\", StringType(), True),\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"uri\", StringType(), True),\n",
    "        StructField(\"track_href\", StringType(), True),\n",
    "        StructField(\"analysis_url\", StringType(), True),\n",
    "        StructField(\"duration_ms\", LongType(), True),\n",
    "        StructField(\"time_signature\", IntegerType(), True)\n",
    "    ])\n",
    "\n",
    "    if 'artist' in table_name:\n",
    "        return artist_schema\n",
    "    elif 'album' in table_name:\n",
    "        return album_schema\n",
    "    elif 'feature' in table_name:\n",
    "        return track_features_schema\n",
    "    else:\n",
    "        return track_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d50f0a-a2a4-4aad-8294-d71a9c7b6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bronze_layer_task(spark: SparkSession, database_name: str, table_name: str) -> None:\n",
    "    \"\"\"Extract data from MongoDB to HDFS at bronze layer\"\"\"\n",
    "    user = os.getenv(\"MONGODB_USER\")\n",
    "    password = os.getenv(\"MONGODB_PASSWORD\")\n",
    "    hdfs_uri = f\"hdfs://namenode:8020/bronze_layer/{table_name}.parquet\"\n",
    "    mongo_uri = f\"mongodb+srv://{user}:{password}@python.zynpktu.mongodb.net/?retryWrites=true&w=majority\"\n",
    "    \n",
    "    spark_data = (spark.read.format(\"mongodb\")\n",
    "              .schema(getSchema(table_name))\n",
    "              .option(\"uri\", mongo_uri)\n",
    "              .option('database', database_name)\n",
    "              .option('collection', table_name)\n",
    "              .load()\n",
    "              .select([col for col in getSchema(table_name).fieldNames() if col != '_id'])\n",
    "              )\n",
    "    # Exclude _id field\n",
    "    print(f\"Writing {table_name}\")\n",
    "    try:\n",
    "        spark_data.write.parquet(hdfs_uri, mode=\"overwrite\")\n",
    "        print(f\"Bronze: Successfully push {table_name}.parquet\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(spark_data.printSchema())\n",
    "        # spark_data = (spark.read.format(\"mongodb\")\n",
    "        #       .schema(getSchema(table_name))\n",
    "        #       .option(\"uri\", mongo_uri)\n",
    "        #       .option('database', database_name)\n",
    "        #       .option('collection', table_name)\n",
    "        #       .load()\n",
    "        #       .select([col for col in getSchema(table_name).fieldNames() if col != '_id'])\n",
    "        #       )\n",
    "        # spark_data.write.parquet(hdfs_uri, mode=\"overwrite\")\n",
    "        # print(f\"Bronze: Successfully push {table_name}.parquet\")\n",
    "\n",
    "def IngestHadoop(spark: SparkSession):\n",
    "    \"\"\"Extract data From MongoDb and Load to HDFS\"\"\"\n",
    "\n",
    "    # Connect to MongoDB\n",
    "\n",
    "    # database_name = \"remake_spotify_crawling_data\"\n",
    "    database_name = os.getenv(\"MONGODB_DATABASE\")\n",
    "    \n",
    "    \n",
    "    with MongodbIO() as client:\n",
    "        mongo_db = client[database_name] \n",
    "        collections = mongo_db.list_collection_names() #get all collectons\n",
    "    \n",
    "        #Running task concurrently\n",
    "        for collection in collections:\n",
    "            print(f\"{collection} start being Ingested...\")\n",
    "            bronze_layer_task(spark, database_name, collection) #collection is also the name of table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a68bbd-bcdc-436a-8233-c1631e7dcc5d",
   "metadata": {},
   "source": [
    "There is 4 tables:\n",
    "- artists_data.parquet\n",
    "- songs_data.parquet\n",
    "- genres_data.parquet\n",
    "- albums_data.parquet\n",
    "\n",
    "location: hdfs://namenode:8020/bronze_layer/{table_name}.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae751864-38fa-439c-86ba-25f8c5d0c5ef",
   "metadata": {},
   "source": [
    "## Silver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf39cf0-e570-41a0-be62-98be23c834a7",
   "metadata": {},
   "source": [
    "### Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e29de1-4be3-4ea6-a908-ab545adb3c48",
   "metadata": {},
   "source": [
    "![Schema](./spotify.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c92ca9-4f92-461c-819a-2f6c2c70278a",
   "metadata": {},
   "source": [
    "Target: \n",
    "- using pyspark Cleaning, droping duplicated, drop unusable column (Read [EDA](https://colab.research.google.com/drive/15uM8Uvj1I89zjtJrVn-Z7mvkfyCWo50T?usp=sharing)), format type, there are many duplicated observation.\n",
    "- join dim artist and dim albums -> join_artist_albums table (clean table before merge) (task 1)\n",
    "- clean genre, then write back to silver(task 2) -> clean_genre table\n",
    "- clean songs (task 3) -> clean_songs table (return None)\n",
    "- The location of silver: hdfs_uri = f\"hdfs://namenode:8020/silver_layer/{table_name}.parquet\" with table_name is name of result table\n",
    "\n",
    "\n",
    "Requirements:\n",
    "- Input of silver main task (spark session), Output: None\n",
    "- silver main task may have many child tasks, concurrently or sequencially\n",
    "- Child task input (spark session), any extended params or return base on you, ensure write back result in hdfs with related uri\n",
    "- Writing (print out) logs every action, handle error and exception (raise it if neccesary)\n",
    "\n",
    "Dont forget to add your main task to main function !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d88006a-e33c-403e-b407-1135f16817de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some code here\n",
    "def silver_layer_task(spark: SparkSession):\n",
    "    '''Do some Cleaning tasks for silver layer'''\n",
    "    # task 1\n",
    "    # task 2\n",
    "    # task 3 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dabde27-5933-4ef3-8175-e04b07d83cfd",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb1e0e4-6556-4a1c-a220-acd50f895285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_B():\n",
    "    \"\"\"ELT pipeline with pyspark\"\"\"\n",
    "\n",
    "    user = os.getenv(\"MONGODB_USER\")\n",
    "    password = os.getenv(\"MONGODB_PASSWORD\")\n",
    "    uri = f\"mongodb+srv://{user}:{password}@python.zynpktu.mongodb.net/?retryWrites=true&w=majority\"\n",
    "    conf = (SparkConf().setAppName(\"ETL-app-{}\".format(datetime.today()))\n",
    "        .set(\"spark.executor.memory\", \"2g\")\n",
    "        .set(\"spark.mongodb.read.connection.uri\",uri)\n",
    "        .set(\"spark.mongodb.write.connection.uri\", uri)\n",
    "        .set(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.2.1\")\n",
    "        .setMaster(\"local[*]\")\n",
    "        )\n",
    "\n",
    "    with SparkIO(conf) as spark:\n",
    "        IngestHadoop(spark) # <----- bronze task\n",
    "        # add silver tasks here <-------\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f14c330-c89d-4a78-99b7-dc627e2b1704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create SparkSession app ETL-app-2023-12-04 10:38:41.571238 with local[*] mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.11/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7b76f791-c9f1-4d6c-8833-707f81420baa;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;10.2.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.8.2 in central\n",
      "\t[4.8.2] org.mongodb#mongodb-driver-sync;[4.8.1,4.8.99)\n",
      "\tfound org.mongodb#bson;4.8.2 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.8.2 in central\n",
      "\tfound org.mongodb#bson-record-codec;4.8.2 in central\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/10.2.1/mongo-spark-connector_2.12-10.2.1.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb.spark#mongo-spark-connector_2.12;10.2.1!mongo-spark-connector_2.12.jar (712ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-sync/4.8.2/mongodb-driver-sync-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-sync;4.8.2!mongodb-driver-sync.jar (397ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/bson/4.8.2/bson-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#bson;4.8.2!bson.jar (637ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-core/4.8.2/mongodb-driver-core-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-core;4.8.2!mongodb-driver-core.jar (560ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/bson-record-codec/4.8.2/bson-record-codec-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#bson-record-codec;4.8.2!bson-record-codec.jar (202ms)\n",
      ":: resolution report :: resolve 12502ms :: artifacts dl 2516ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.8.2 from central in [default]\n",
      "\torg.mongodb#bson-record-codec;4.8.2 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.8.2 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.8.2 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;10.2.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   5   |   5   |   0   ||   5   |   5   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7b76f791-c9f1-4d6c-8833-707f81420baa\n",
      "\tconfs: [default]\n",
      "\t5 artifacts copied, 0 already retrieved (2370kB/13ms)\n",
      "23/12/04 10:38:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB Connected\n",
      "tracks_features_data start being Ingested...\n",
      "Writing tracks_features_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/04 10:39:06 WARN FileSystem: Failed to initialize fileystem hdfs://namenode:8020/bronze_layer/tracks_features_data.parquet: java.lang.IllegalArgumentException: java.net.UnknownHostException: namenode\n",
      "23/12/04 10:39:06 WARN FileSystem: Failed to initialize fileystem hdfs://namenode:8020/bronze_layer/artists_data.parquet: java.lang.IllegalArgumentException: java.net.UnknownHostException: namenode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java.net.UnknownHostException: namenode\n",
      "root\n",
      " |-- danceability: double (nullable = true)\n",
      " |-- energy: double (nullable = true)\n",
      " |-- key: integer (nullable = true)\n",
      " |-- loudness: double (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- speechiness: double (nullable = true)\n",
      " |-- acousticness: double (nullable = true)\n",
      " |-- instrumentalness: double (nullable = true)\n",
      " |-- liveness: double (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: double (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- uri: string (nullable = true)\n",
      " |-- track_href: string (nullable = true)\n",
      " |-- analysis_url: string (nullable = true)\n",
      " |-- duration_ms: long (nullable = true)\n",
      " |-- time_signature: integer (nullable = true)\n",
      "\n",
      "None\n",
      "artists_data start being Ingested...\n",
      "Writing artists_data\n",
      "java.net.UnknownHostException: namenode\n",
      "root\n",
      " |-- external_urls: struct (nullable = true)\n",
      " |    |-- spotify: string (nullable = true)\n",
      " |-- followers: struct (nullable = true)\n",
      " |    |-- href: string (nullable = true)\n",
      " |    |-- total: integer (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- href: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- height: integer (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- width: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- popularity: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- uri: string (nullable = true)\n",
      "\n",
      "None\n",
      "tracks_data start being Ingested...\n",
      "Writing tracks_data\n",
      "java.net.UnknownHostException: namenode\n",
      "root\n",
      " |-- disc_number: integer (nullable = true)\n",
      " |-- duration_ms: long (nullable = true)\n",
      " |-- explicit: boolean (nullable = true)\n",
      " |-- external_ids: struct (nullable = true)\n",
      " |    |-- isrc: string (nullable = true)\n",
      " |-- external_urls: struct (nullable = true)\n",
      " |    |-- spotify: string (nullable = true)\n",
      " |-- href: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_local: boolean (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- popularity: integer (nullable = true)\n",
      " |-- preview_url: string (nullable = true)\n",
      " |-- track_number: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- uri: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- album_id: string (nullable = true)\n",
      "\n",
      "None\n",
      "albums_data start being Ingested...\n",
      "Writing albums_data\n",
      "java.net.UnknownHostException: namenode\n",
      "root\n",
      " |-- album_type: string (nullable = true)\n",
      " |-- copyrights: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- external_ids: struct (nullable = true)\n",
      " |    |-- upc: string (nullable = true)\n",
      " |-- external_urls: struct (nullable = true)\n",
      " |    |-- spotify: string (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- href: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- height: integer (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- width: integer (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- popularity: integer (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- release_date_precision: string (nullable = true)\n",
      " |-- total_tracks: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- uri: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      "\n",
      "None\n",
      "Close connection to MongoDB\n",
      "Stop SparkSession app ETL-app-2023-12-04 10:38:41.571238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/04 10:39:06 WARN FileSystem: Failed to initialize fileystem hdfs://namenode:8020/bronze_layer/tracks_data.parquet: java.lang.IllegalArgumentException: java.net.UnknownHostException: namenode\n",
      "23/12/04 10:39:06 WARN FileSystem: Failed to initialize fileystem hdfs://namenode:8020/bronze_layer/albums_data.parquet: java.lang.IllegalArgumentException: java.net.UnknownHostException: namenode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 112 ms, total: 216 ms\n",
      "Wall time: 25.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/04 10:40:11 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/spark-9bce2320-fc6c-406c-b34b-4f970cfef456/pyspark-3df822b5-5afd-418c-808d-c6a73d2967ad. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/spark-9bce2320-fc6c-406c-b34b-4f970cfef456/pyspark-3df822b5-5afd-418c-808d-c6a73d2967ad\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1193)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6b2c652-689b-43a2-b910-4ca0ad8215cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179437"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = (SparkConf().setAppName(\"ETL-app-{}\".format(datetime.today()))\n",
    "        .set(\"spark.executor.memory\", \"2g\")\n",
    "        .setMaster(\"local[*]\")\n",
    "        )\n",
    "\n",
    "table_name = 'silver_tracks'\n",
    "layer = 'silver_layer'\n",
    "hdfs_uri = f\"hdfs://namenode:8020/{layer}/{table_name}.parquet\"\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "df = spark.read.parquet(hdfs_uri, inferSchema=True)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d75a5b12-46fd-4e4f-9647-064bc32969d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- disc_number: integer (nullable = true)\n",
      " |-- duration_ms: long (nullable = true)\n",
      " |-- explicit: boolean (nullable = true)\n",
      " |-- external_ids: struct (nullable = true)\n",
      " |    |-- isrc: string (nullable = true)\n",
      " |-- external_urls: string (nullable = true)\n",
      " |-- href: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_local: boolean (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- popularity: integer (nullable = true)\n",
      " |-- preview_url: string (nullable = true)\n",
      " |-- track_number: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- uri: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- album_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e94fdc8-953a-4eee-a814-32d4df84195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('id', 'track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d98fa7b4-1324-45df-9754-589bd557f314",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'id' given input columns: [album_id, artist_id, disc_number, duration_ms, explicit, external_ids, external_urls, href, is_local, name, popularity, preview_url, track_id, track_number, type, uri];\n'Project ['id]\n+- Project [disc_number#35, duration_ms#36L, explicit#37, external_ids#38, external_urls#39, href#40, id#41 AS track_id#95, is_local#42, name#43, popularity#44, preview_url#45, track_number#46, type#47, uri#48, artist_id#49, album_id#50]\n   +- Relation [disc_number#35,duration_ms#36L,explicit#37,external_ids#38,external_urls#39,href#40,id#41,is_local#42,name#43,popularity#44,preview_url#45,track_number#46,type#47,uri#48,artist_id#49,album_id#50] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyspark/sql/dataframe.py:1685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols):\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1685\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'id' given input columns: [album_id, artist_id, disc_number, duration_ms, explicit, external_ids, external_urls, href, is_local, name, popularity, preview_url, track_id, track_number, type, uri];\n'Project ['id]\n+- Project [disc_number#35, duration_ms#36L, explicit#37, external_ids#38, external_urls#39, href#40, id#41 AS track_id#95, is_local#42, name#43, popularity#44, preview_url#45, track_number#46, type#47, uri#48, artist_id#49, album_id#50]\n   +- Relation [disc_number#35,duration_ms#36L,explicit#37,external_ids#38,external_urls#39,href#40,id#41,is_local#42,name#43,popularity#44,preview_url#45,track_number#46,type#47,uri#48,artist_id#49,album_id#50] parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/10 07:01:48 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-801c6fcb-c0d0-42a2-87f1-660fc8a1182e. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-801c6fcb-c0d0-42a2-87f1-660fc8a1182e\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1193)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:318)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:314)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:314)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:309)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2013)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:92)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2136)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1471)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2136)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$38(SparkContext.scala:677)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "df.select('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f3b3cf9-df90-4e6b-b143-ae482a581f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "from pyarrow import flight\n",
    "import pandas as pd\n",
    "\n",
    "class DremioClient:\n",
    "    def __init__(self, host, port, uid, pwd) -> None:\n",
    "        self._host = host\n",
    "        self._port = port\n",
    "        self._uid = uid\n",
    "        self._pwd = pwd\n",
    "\n",
    "    def connect(self):\n",
    "        self._client = flight.FlightClient(f\"grpc://{self._host}:{self._port}\")\n",
    "\n",
    "    def authenticate(self):\n",
    "        bearer_token = self._client.authenticate_basic_token(\n",
    "            self._uid, self._pwd)\n",
    "        options = flight.FlightCallOptions(headers=[bearer_token])\n",
    "        return options\n",
    "\n",
    "    def query(self, sql, options):\n",
    "        info = self._client.get_flight_info(\n",
    "            flight.FlightDescriptor.for_command(sql), options=options)\n",
    "        reader = self._client.do_get(info.endpoints[0].ticket, options=options)\n",
    "        df = reader.read_all().to_pandas()\n",
    "        return df\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     client = DremioClient()\n",
    "#     client.connect()\n",
    "#     options = client.authenticate()\n",
    "#     location = \"home.tracks\"\n",
    "#     df = client.query(\n",
    "#         f\"SELECT * FROM {location}\", options)\n",
    "#     print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2b0e730-b7c7-4d59-b6ae-4d9ac421b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = DremioClient('dremio', 32010, 'dremio', 'dremio123')\n",
    "client.connect()\n",
    "options = client.authenticate()\n",
    "location = \"home.artist\"\n",
    "data_artist = client.query(\n",
    "    f\"SELECT * FROM {location}\", options)\n",
    "data_genre = client.query(\"SELECT * FROM home.genre\", options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "311ecb18-313f-45df-a06a-7da253568025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       object\n",
       "genre    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_genre.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2213492c-a2ef-45f6-b155-9f80676d8aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>followers</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00FQb4jTyendYWaN8pK0wa</td>\n",
       "      <td>Lana Del Rey</td>\n",
       "      <td>88</td>\n",
       "      <td>30274665</td>\n",
       "      <td>pop, art pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00XhexlJEXQstHimpZN910</td>\n",
       "      <td>Brytiago</td>\n",
       "      <td>73</td>\n",
       "      <td>6779721</td>\n",
       "      <td>urbano latino, reggaeton, trap latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00me4Ke1LsvMxt5kydlMyU</td>\n",
       "      <td>Cosculluela</td>\n",
       "      <td>71</td>\n",
       "      <td>5829767</td>\n",
       "      <td>trap latino, latin hip hop, reggaeton, urbano ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>014WIDx7H4BRCHB1faiisK</td>\n",
       "      <td>Los Tucanes De Tijuana</td>\n",
       "      <td>74</td>\n",
       "      <td>2775114</td>\n",
       "      <td>musica mexicana, corrido, musica bajacaliforni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02kJSzxNuaWGqwubyUba0Z</td>\n",
       "      <td>G-Eazy</td>\n",
       "      <td>73</td>\n",
       "      <td>5227026</td>\n",
       "      <td>pop rap, rap, oakland hip hop, indie pop rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>7vk5e3vY1uw9plTHJAMwjN</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>78</td>\n",
       "      <td>39860778</td>\n",
       "      <td>electro house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>7wlFDEWiM5OoIAt8RSli8b</td>\n",
       "      <td>YoungBoy Never Broke Again</td>\n",
       "      <td>81</td>\n",
       "      <td>12150119</td>\n",
       "      <td>rap, baton rouge rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>7x8nK0m0cP2ksQf0mjWdPS</td>\n",
       "      <td>Dierks Bentley</td>\n",
       "      <td>65</td>\n",
       "      <td>3090951</td>\n",
       "      <td>country road, contemporary country, country, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>7xeM7V59cA1X8GKyKKQV87</td>\n",
       "      <td>Sin Bandera</td>\n",
       "      <td>69</td>\n",
       "      <td>5909562</td>\n",
       "      <td>mexican pop, latin arena pop, latin pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>7z5WFjZAIYejWy0NI5lv4T</td>\n",
       "      <td>Dan + Shay</td>\n",
       "      <td>70</td>\n",
       "      <td>3100876</td>\n",
       "      <td>country road, contemporary country, country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                        name  popularity  \\\n",
       "0    00FQb4jTyendYWaN8pK0wa                Lana Del Rey          88   \n",
       "1    00XhexlJEXQstHimpZN910                    Brytiago          73   \n",
       "2    00me4Ke1LsvMxt5kydlMyU                 Cosculluela          71   \n",
       "3    014WIDx7H4BRCHB1faiisK      Los Tucanes De Tijuana          74   \n",
       "4    02kJSzxNuaWGqwubyUba0Z                      G-Eazy          73   \n",
       "..                      ...                         ...         ...   \n",
       "990  7vk5e3vY1uw9plTHJAMwjN                 Alan Walker          78   \n",
       "991  7wlFDEWiM5OoIAt8RSli8b  YoungBoy Never Broke Again          81   \n",
       "992  7x8nK0m0cP2ksQf0mjWdPS              Dierks Bentley          65   \n",
       "993  7xeM7V59cA1X8GKyKKQV87                 Sin Bandera          69   \n",
       "994  7z5WFjZAIYejWy0NI5lv4T                  Dan + Shay          70   \n",
       "\n",
       "     followers                                              genre  \n",
       "0     30274665                                       pop, art pop  \n",
       "1      6779721              urbano latino, reggaeton, trap latino  \n",
       "2      5829767  trap latino, latin hip hop, reggaeton, urbano ...  \n",
       "3      2775114  musica mexicana, corrido, musica bajacaliforni...  \n",
       "4      5227026       pop rap, rap, oakland hip hop, indie pop rap  \n",
       "..         ...                                                ...  \n",
       "990   39860778                                      electro house  \n",
       "991   12150119                               rap, baton rouge rap  \n",
       "992    3090951  country road, contemporary country, country, m...  \n",
       "993    5909562            mexican pop, latin arena pop, latin pop  \n",
       "994    3100876        country road, contemporary country, country  \n",
       "\n",
       "[995 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_library = data_artist.merge( data_genre, on='id')\n",
    "artist_library\n",
    "grouped_df = artist_library.groupby('id').agg({'name': 'first', 'popularity': 'first', 'followers': 'first', 'genre': lambda x: ', '.join(x)})\n",
    "\n",
    "# Reset the index to make 'artist_id' a column again\n",
    "artist_library = grouped_df.reset_index()\n",
    "artist_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6bc04-4b37-49f4-be0b-3fb4a569e3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
